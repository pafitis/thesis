{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39264bitcomp0087conda439ae987b69d4c2b958b538715e3f45b",
   "display_name": "Python 3.9.2 64-bit ('comp0087': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6b9679e1c6c858221750b0560d352a46169916bc602dce44bbd2a48d631c8c5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# June - Wed 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Focus on getting data ready"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### What I've done:\n",
    "I completed my exams! I took a much needed break and now started on my dissertation.\n",
    "\n",
    "This means I:\n",
    "\n",
    "1. Contacted ONS, not particularly helpful. I did get a contact for the publishing team that handles the API. \n",
    "2. I got together a quick \"scraper\". Use requests/ beautifulsoup to talk to ons.com/releasecalendar\n",
    "3. I extract: \n",
    "    - title,\n",
    "    - link,\n",
    "    - relevant publications,\n",
    "    - relevant datasets,\n",
    "    - metadata\n",
    "4. From here, I wrote a dirty processing \"pipeline\" that extracts text from *relevant publications*\n",
    "    - Some entries do not have publications but do have datasets. There are papers that can generate sentences that logically follow the contents of the table. I am not investing time in this path (currently). **Should I?**       \n",
    "    - Almost all \"Main-Points\" sections are in list form. Easy to extract, quickstart.\n",
    "    - **Am I limiting myself too much if I just focus on such sentences?**\n",
    "    - (I am using `<li>` tags to extract such sentences, and I see that they are more self contained than `<p>` counterparts; naturally)\n",
    "5. Preliminary investigation into *relevant datasets* show that they are extremely messy.\n",
    "    - No consistentcy in sheet naming scheme\n",
    "    - Whether cover pages are included or not\n",
    "    - Column names are dirty\n",
    "    - Headers, etc etc...\n",
    "    - **This will be hell** but hopefully the API solves this"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Publications\n",
    "\n",
    "From here, I wrote a dirty processing \"pipeline\". I learned that:\n",
    "\n",
    "1. Not all entries have publications. Some just have datasets. Either ignore such entries and focus on those that *DO* have publications, or I would need to figure out a way to generate appropriate sentences that correspond to the tables.\n",
    "2. I found two papers that discuss how one can generate sentences that follow logically from tabular data. (J. Cheng people that worked on TabFact)\n",
    "    - [Logical Natural Language Generation from Open-Domain Tables](https://www.aclweb.org/anthology/2020.acl-main.708/)\n",
    "    - [Logic2Text: High-Fidelity Natural Language Generation from Logical Forms](https://arxiv.org/abs/2004.14579)\n",
    "3. I am not investing time following this path. **good call?**\n",
    "4. Most publications consistently start with **Main Points** section.\n",
    "    - Bullet point sentences\n",
    "    - Easy to extract and to the point\n",
    "    - Summarise the accompanying datasets\n",
    "5. **NOT ALL PUBLICATIONS HAVE MAIN POINTS SECTION**\n",
    "6. This means that content is presented in paragraph format.\n",
    "7. My pipeline utilises html `<li>` and `<p>` tags to extract sentences. List formated sentences are much cleaner. \n",
    "8. I need to figure out a way to distinguish sentences of interest WITHIN a paragraph.\n",
    "    - For example these two sentences are excerpts from a larger paragraph. The first arguably can be used in our work, the second not so much.\n",
    "        - The Kickstart Scheme, launched in September 2020, is a Â£2 billion fund to create six-month work placements for those aged 16 to 24 years who receive Universal Credit and are deemed to be at risk of long-term unemployment.\n",
    "        - Following a classification review, we concluded that the ERMAs placed TOCs under public sector control.\n",
    "8. Particularly I took the liberty to:\n",
    "    - Removed any references to Twitter, Office of National Statistics (these were to refer reader to other socials/ pages).\n",
    "    - Removed sentences that contain `|` character (these were only found in related links and separate contact info, which we do not want)\n",
    "    - Removed sentences \"Totals may not sum due to rounding\". There are similar ones like \"Averages are calculated as simple averages\". There isn't a clear/ automatic way to remove all these. **I suspect that there will be a lot of repetition in language so maybe we can `grep` specific keywords**\n",
    "    - Removed whitespaces and some quotation mark artifacts from scraping\n",
    "    - Removed sentences that contain urls. None were talking about the actual table/data contents."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Datasets\n",
    "\n",
    "The "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}