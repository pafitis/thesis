{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tapas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, logging, spacy, sys, os, json, requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.classes import Collection\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from helpers.cloze_generation import generate_clozes_from_point, named_entity_answer_generator as ne_answer_generator, noun_phrase_answer_generator as np_answer_generator\n",
    "\n",
    "from helpers.table_processing import preprocess_table\n",
    "\n",
    "from helpers.language_modelling import run_language_model, summarise_results\n",
    "\n",
    "df = pd.read_pickle('pickles/dataset_20210625_184837.pkl')\n",
    "clozes_df = pd.read_json('pickles/clozes_20210715_212425.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering, TapasForMaskedLM\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def replace_mask(\n",
    "    sentence, \n",
    "    masks = ['IDENTITYMASK', 'NOUNPHRASEMASK', 'NUMERICMASK', \n",
    "        'PLACEMASK', 'TEMPORALMASK', 'THINGMASK']):\n",
    "\n",
    "    # somewhat hacky\n",
    "    # checks if sentence contains any of the masks\n",
    "    # and replaces it with the appropriate tokenizer.mask_token\n",
    "    x = [sentence.replace(x, tokenizer.mask_token) \\\n",
    "        for x in masks if x in sentence]\n",
    "    if len(x):\n",
    "        return x[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model_name = 'google/tapas-base-finetuned-wtq'\n",
    "# model = TapasForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
    "model = TapasForMaskedLM.from_pretrained(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at google/tapas-base-finetuned-wtq were not used when initializing TapasForMaskedLM: ['output_weights', 'column_output_weights', 'output_bias', 'column_output_bias', 'aggregation_classifier.weight', 'aggregation_classifier.bias', 'tapas.pooler.dense.weight', 'tapas.pooler.dense.bias']\n",
      "- This IS expected if you are initializing TapasForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TapasForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TapasForMaskedLM were not initialized from the model checkpoint at google/tapas-base-finetuned-wtq and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "row = df.iloc[0]\n",
    "point = row.point\n",
    "datasets = row.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "clozes = [c for c in generate_clozes_from_point(point, ne_answer_generator)]\n",
    "queries = [replace_mask(c.cloze_text) for c in clozes]\n",
    "data = datasets[2].replace('/', '_')[1:]\n",
    "excel_file = pd.ExcelFile('datasets/' + data + '.xls')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "excel_file.sheet_names"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Contents',\n",
       " 'Non-Financial Business Economy',\n",
       " 'Section-Division by Region',\n",
       " 'Region by Section-Division']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data = excel_file.parse('Non-Financial Business Economy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "table = preprocess_table(data).astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "inputs = tokenizer(\n",
    "    table=table, queries=queries, padding='max_length', return_tensors='pt',\n",
    "    truncation=True)\n",
    "outputs = model(**inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs,\n",
    "    outputs.logits.detach(),\n",
    "    outputs.logits_aggregation.detach())"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'MaskedLMOutput' object has no attribute 'logits_aggregation'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f695d5346270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     outputs.logits_aggregation.detach())\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaskedLMOutput' object has no attribute 'logits_aggregation'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "outputs.logits"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.6350,  1.5058,  1.0321,  ...,  0.6752,  0.7180,  0.2368],\n",
       "         [ 0.6961,  1.5810,  0.8884,  ...,  0.9269,  0.7713,  0.2906],\n",
       "         [ 0.6243,  1.5662,  0.7142,  ...,  0.7459,  0.6767,  0.0153],\n",
       "         ...,\n",
       "         [ 0.4787,  1.3786,  0.7702,  ...,  0.3810,  0.2486, -0.3435],\n",
       "         [ 0.4895,  1.2159,  0.4182,  ...,  0.6613,  0.3502, -0.1579],\n",
       "         [ 0.4811,  1.3290,  0.5368,  ...,  0.3885,  0.2259, -0.3842]],\n",
       "\n",
       "        [[ 0.3978,  1.0193,  0.2453,  ...,  0.0290,  0.2707, -0.7794],\n",
       "         [ 0.7116,  1.4247,  0.5465,  ...,  0.4968,  0.3723, -0.3773],\n",
       "         [ 0.5248,  0.9254,  0.3521,  ..., -0.2599, -0.0825, -1.1861],\n",
       "         ...,\n",
       "         [ 0.5370,  1.3793,  0.8873,  ...,  0.0156,  0.2127, -0.4465],\n",
       "         [ 0.4518,  1.0105,  0.2540,  ...,  0.1124,  0.1644, -0.5547],\n",
       "         [ 0.6188,  1.3363,  0.6226,  ...,  0.0611,  0.1498, -0.3889]],\n",
       "\n",
       "        [[ 0.6078,  1.3986,  0.9694,  ...,  0.6749,  0.6821,  0.0290],\n",
       "         [ 0.6308,  1.4682,  0.8810,  ...,  0.7553,  0.6596,  0.0301],\n",
       "         [ 0.4687,  1.2889,  0.7328,  ...,  0.2954,  0.2071, -0.3654],\n",
       "         ...,\n",
       "         [ 0.2633,  0.1033,  0.8595,  ..., -0.2494,  0.3136, -0.1222],\n",
       "         [ 0.3381,  1.2077,  0.3752,  ...,  0.3964,  0.2223, -0.3808],\n",
       "         [ 0.4596,  1.3985,  0.7514,  ...,  0.1891,  0.2663, -0.4330]],\n",
       "\n",
       "        [[ 0.6001,  1.3693,  0.7816,  ...,  0.5696,  0.6590, -0.1080],\n",
       "         [ 0.5846,  1.5119,  0.5594,  ...,  0.6380,  0.4679, -0.1500],\n",
       "         [ 0.5606,  1.3086,  0.4699,  ...,  0.2955,  0.2186, -0.3897],\n",
       "         ...,\n",
       "         [ 0.3041,  0.0398,  0.8973,  ..., -0.2111,  0.2851, -0.0521],\n",
       "         [ 0.2483, -0.0362,  0.8007,  ..., -0.2302,  0.2665, -0.1306],\n",
       "         [ 0.5222,  1.5053,  0.6251,  ...,  0.0747,  0.1865, -0.4423]],\n",
       "\n",
       "        [[ 0.5789,  1.4947,  0.9887,  ...,  0.5945,  0.7104,  0.0984],\n",
       "         [ 0.6018,  1.6085,  0.6976,  ...,  0.7695,  0.6129,  0.0916],\n",
       "         [ 0.5466,  1.4635,  0.6517,  ...,  0.5542,  0.3386, -0.0669],\n",
       "         ...,\n",
       "         [ 0.4662,  1.4593,  0.7846,  ...,  0.3037,  0.2552, -0.3289],\n",
       "         [ 0.3902,  1.2717,  0.3934,  ...,  0.5387,  0.2938, -0.2198],\n",
       "         [ 0.4865,  1.4362,  0.5662,  ...,  0.4353,  0.3339, -0.2590]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('comp0087': conda)"
  },
  "interpreter": {
   "hash": "6b9679e1c6c858221750b0560d352a46169916bc602dce44bbd2a48d631c8c5d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}