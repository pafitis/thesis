{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, logging, spacy, sys, os, json, requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.classes import Collection\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# DATASETS = os.listdir('datasets')\n",
    "\n",
    "# with open('pickles/collection_20210624_194932.pkl', 'rb') as f:\n",
    "#     collection = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# # I should completely remove the other bulletins\n",
    "# # for now this has to do...\n",
    "# bulletin_names = list(collection.bulletins.keys())\n",
    "# # target bulletins are those with usable related datasets and main points\n",
    "# target_bulletins = []\n",
    "# dictionary = dict()\n",
    "# for bulletin in bulletin_names:\n",
    "#     if len(collection.bulletins.get(bulletin).get('main-points')) and len(collection.bulletins.get(bulletin).get('related-datasets')) > 0:\n",
    "#         target_bulletins.append(bulletin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from helpers.cloze_generation import generate_clozes_from_point, named_entity_answer_generator as ne_answer_generator, noun_phrase_answer_generator as np_answer_generator\n",
    "\n",
    "df = pd.read_pickle('pickles/dataset_20210625_184837.pkl')\n",
    "clozes_df = pd.read_json('pickles/clozes_20210715_212425.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            bulletin              type  \\\n",
       "0  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "1  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "2  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "3  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "4  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "\n",
       "                                               point  \\\n",
       "0  In 2019, approximate gross value added at basi...   \n",
       "1  The non-financial services sector, which accou...   \n",
       "2  Total turnover and purchases of the UK non-fin...   \n",
       "3  Out of the 12 UK regions, 8 regions experience...   \n",
       "4  West Midlands, Yorkshire and The Humber, Scotl...   \n",
       "\n",
       "                                                data  \n",
       "0  [/businessindustryandtrade/business/businessse...  \n",
       "1  [/businessindustryandtrade/business/businessse...  \n",
       "2  [/businessindustryandtrade/business/businessse...  \n",
       "3  [/businessindustryandtrade/business/businessse...  \n",
       "4  [/businessindustryandtrade/business/businessse...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bulletin</th>\n",
       "      <th>type</th>\n",
       "      <th>point</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>In 2019, approximate gross value added at basi...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>The non-financial services sector, which accou...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>Total turnover and purchases of the UK non-fin...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>Out of the 12 UK regions, 8 regions experience...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>West Midlands, Yorkshire and The Humber, Scotl...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "from helpers.configs import CLOZE_MASKS\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/bert_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/bert_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/bert_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/bert_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/bert_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/bert_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('BertBase Correct Predictions Snippet')\n",
    "correct_preds[:50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('BertBase Incorrect Predictions Snippet')\n",
    "wrong_preds[:50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/roberta_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/roberta_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/roberta_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/roberta_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/roberta_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/roberta_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Roberta Base Correct Predictions Snippet')\n",
    "correct_preds[:50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Roberta Base Incorrect Predictions Snippet')\n",
    "wrong_preds[:50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Electra"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import ElectraForMaskedLM, ElectraTokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "model = ElectraForMaskedLM.from_pretrained('google/electra-small-discriminator')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/electra_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/electra_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/electra_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/electra_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/electra_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/electra_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Albert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
    "model = AlbertForMaskedLM.from_pretrained('albert-base-v2')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/albert_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/albert_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/albert_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/albert_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/albert_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/albert_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Albert Base Correct Predictions Snippet')\n",
    "correct_preds[:50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Albert Base Incorrect Predictions Snippet')\n",
    "wrong_preds[:50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Token Language Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('results/RobertaForMaskedLM_20210714_192239_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/RobertaForMaskedLM_20210714_192239_entity_set.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/RobertaForMaskedLM_20210714_192239_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)\n",
    "\n",
    "\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizerFast\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            # THIS IS AN ISSUE!!\n",
    "            # IT SEEMS THAT THE MODEL PREDICTS A WHITESPACE AT THE START!!!\n",
    "            if entry[0][0] == ' ':\n",
    "                entry[0] = entry[0][1:]\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b9679e1c6c858221750b0560d352a46169916bc602dce44bbd2a48d631c8c5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('comp0087': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}