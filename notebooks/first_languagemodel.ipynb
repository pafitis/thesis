{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, logging, spacy, sys, os, json, requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.classes import Collection\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# DATASETS = os.listdir('datasets')\n",
    "\n",
    "# with open('pickles/collection_20210624_194932.pkl', 'rb') as f:\n",
    "#     collection = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# # I should completely remove the other bulletins\n",
    "# # for now this has to do...\n",
    "# bulletin_names = list(collection.bulletins.keys())\n",
    "# # target bulletins are those with usable related datasets and main points\n",
    "# target_bulletins = []\n",
    "# dictionary = dict()\n",
    "# for bulletin in bulletin_names:\n",
    "#     if len(collection.bulletins.get(bulletin).get('main-points')) and len(collection.bulletins.get(bulletin).get('related-datasets')) > 0:\n",
    "#         target_bulletins.append(bulletin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from helpers.cloze_generation import generate_clozes_from_point, named_entity_answer_generator as ne_answer_generator, noun_phrase_answer_generator as np_answer_generator\n",
    "\n",
    "df = pd.read_pickle('pickles/dataset_20210625_184837.pkl')\n",
    "clozes_df = pd.read_json('pickles/clozes_20210715_212425.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            bulletin              type  \\\n",
       "0  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "1  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "2  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "3  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "4  businessindustryandtrade/business/businessserv...  date_and_percent   \n",
       "\n",
       "                                               point  \\\n",
       "0  In 2019, approximate gross value added at basi...   \n",
       "1  The non-financial services sector, which accou...   \n",
       "2  Total turnover and purchases of the UK non-fin...   \n",
       "3  Out of the 12 UK regions, 8 regions experience...   \n",
       "4  West Midlands, Yorkshire and The Humber, Scotl...   \n",
       "\n",
       "                                                data  \n",
       "0  [/businessindustryandtrade/business/businessse...  \n",
       "1  [/businessindustryandtrade/business/businessse...  \n",
       "2  [/businessindustryandtrade/business/businessse...  \n",
       "3  [/businessindustryandtrade/business/businessse...  \n",
       "4  [/businessindustryandtrade/business/businessse...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bulletin</th>\n",
       "      <th>type</th>\n",
       "      <th>point</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>In 2019, approximate gross value added at basi...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>The non-financial services sector, which accou...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>Total turnover and purchases of the UK non-fin...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>Out of the 12 UK regions, 8 regions experience...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>businessindustryandtrade/business/businessserv...</td>\n",
       "      <td>date_and_percent</td>\n",
       "      <td>West Midlands, Yorkshire and The Humber, Scotl...</td>\n",
       "      <td>[/businessindustryandtrade/business/businessse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "from helpers.configs import CLOZE_MASKS\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/bert_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/bert_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/bert_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/bert_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/bert_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/bert_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# I WASNT CONVERTING TO LOWER CASE!!!\n",
    "\n",
    "# count_correct, count_wrong = 0, 0\n",
    "# correct_preds, wrong_preds = [], []\n",
    "\n",
    "# for row in results:\n",
    "#     if len(row):\n",
    "#         for entry in row:\n",
    "#             if entry[0] == entry[2]:\n",
    "#                 count_correct += 1\n",
    "#                 correct_preds.append(entry[0])\n",
    "#             else:\n",
    "#                 count_wrong += 1\n",
    "#                 wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "# print(f'Total Examples: {count_wrong + count_correct}')\n",
    "# print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "# print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Examples: 6184\n",
      "Correct: 179, Incorrect: 6005\n",
      "Percentage Correct: 2.895%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if str(entry[0]).lower() == str(entry[2]).lower():\n",
    "                count_correct += 1\n",
    "                correct_preds.append(str(entry[0]).lower())\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((str(entry[0]).lower(), str(entry[2]).lower()))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Examples: 6184\n",
      "Correct: 654, Incorrect: 5530\n",
      "Percentage Correct: 10.576%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print('BertBase Correct Predictions Snippet')\n",
    "correct_preds[:50]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BertBase Correct Predictions Snippet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['2019',\n",
       " '2018',\n",
       " 'year',\n",
       " 'scotland',\n",
       " '2019',\n",
       " '2018',\n",
       " 'london',\n",
       " '2018',\n",
       " 'last year',\n",
       " 'london',\n",
       " '2018',\n",
       " '2017',\n",
       " '2017',\n",
       " '2016',\n",
       " '2017',\n",
       " '2016',\n",
       " '2017',\n",
       " '2016',\n",
       " '2016',\n",
       " '2015',\n",
       " '2016',\n",
       " 'london',\n",
       " '2016',\n",
       " 'monthly',\n",
       " '2020',\n",
       " 'london',\n",
       " '2018',\n",
       " 'non-eu',\n",
       " 'non-eu',\n",
       " '2018',\n",
       " '2017',\n",
       " 'europe',\n",
       " 'the united states',\n",
       " 'london',\n",
       " '2018',\n",
       " 'england',\n",
       " 'the previous week',\n",
       " 'the previous week',\n",
       " 'hour',\n",
       " 'nine',\n",
       " 'around one',\n",
       " 'five',\n",
       " 'first',\n",
       " 'first',\n",
       " 'fye 2018',\n",
       " 'fye 2018',\n",
       " 'hours',\n",
       " 'hours',\n",
       " '2016',\n",
       " '2015']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "print('BertBase Incorrect Predictions Snippet')\n",
    "wrong_preds[:50]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BertBase Incorrect Predictions Snippet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('£88 usd. usd billion', '£1,313.9 billion'),\n",
       " ('£.bn.n', '£42.8 billion'),\n",
       " ('(ava ', '3.4%'),\n",
       " ('£,,,,, billion', '£4,101.5 billion'),\n",
       " ('£ in in billion in 2019 2020,', '£2,761.4 billion'),\n",
       " ('. sterling pounds billion sterling', '£70.5 billion'),\n",
       " ('(.% respectively', '1.7%'),\n",
       " ('£. respectivelybillion respectively', '£25.8 billion'),\n",
       " ('( respectively respectively respectively', '0.9%'),\n",
       " ('2016', '2018'),\n",
       " ('the region ireland', 'the south east'),\n",
       " ('.. up increase%', '£17.3 billion'),\n",
       " ('. £ level level billion', '£214.4 billion'),\n",
       " ('£ million expected expected', '8.8%'),\n",
       " ('2017', '2019'),\n",
       " ('</s>western', 'west midlands'),\n",
       " ('northern ireland', 'yorkshire'),\n",
       " ('london', 'scotland'),\n",
       " ('northern ireland', 'east midlands'),\n",
       " ('only', 'four'),\n",
       " (', england', 'west midlands'),\n",
       " ('. or or of%', '£2.5 billion'),\n",
       " ('(-% overall', '2.6%'),\n",
       " ('£. billion in 2016', '£94.5 billion'),\n",
       " ('£ billion billion', '£92 billion'),\n",
       " ('the entire period up', 'from late may 2021'),\n",
       " ('late 2022 levels', 'early june 2021'),\n",
       " ('percent currently', '87%'),\n",
       " ('2016 data', 'june 2020'),\n",
       " ('%%', '31%'),\n",
       " ('the highest ever', 'over 60%'),\n",
       " ('2016 levels', 'january 2021'),\n",
       " ('</s>london', 'wales'),\n",
       " ('the marketplaces', 'early may 2021'),\n",
       " ('percent growth', '87%'),\n",
       " ('other', 'four'),\n",
       " ('the by by', 'late march to'),\n",
       " ('early 2017 onwards', 'early may 2021'),\n",
       " ('thess', 'early november 2020'),\n",
       " ('ireland ireland', 'northern ireland'),\n",
       " ('thess', 'early november 2020'),\n",
       " ('quarterlyly monthly', 'quarterly'),\n",
       " ('most recent', 'annual'),\n",
       " ('of the', 'quarterly'),\n",
       " ('(covid19a-', '27 july to 9 august 2020'),\n",
       " ('percent turnover', '82%'),\n",
       " ('the of the storm', 'the next three months'),\n",
       " ('any level', '34%'),\n",
       " ('%%', '34%'),\n",
       " ('%%', '10%')]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/roberta_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/roberta_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/roberta_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/roberta_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/roberta_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/roberta_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Examples: 6184\n",
      "Correct: 715, Incorrect: 5469\n",
      "Percentage Correct: 11.562%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print('Roberta Base Correct Predictions Snippet')\n",
    "correct_preds[:50]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Roberta Base Correct Predictions Snippet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['2019',\n",
       " '2018',\n",
       " 'Yorkshire',\n",
       " 'year',\n",
       " 'annual',\n",
       " '2019',\n",
       " '2018',\n",
       " '2018',\n",
       " 'London',\n",
       " '2018',\n",
       " '2017',\n",
       " '2017',\n",
       " '2016',\n",
       " '2017',\n",
       " '2016',\n",
       " '2017',\n",
       " '2016',\n",
       " '2016',\n",
       " '2015',\n",
       " '2016',\n",
       " 'London',\n",
       " '2016',\n",
       " 'annual',\n",
       " 'annual',\n",
       " '2020',\n",
       " '2018',\n",
       " 'Yorkshire',\n",
       " '2018',\n",
       " '2017',\n",
       " 'Europe',\n",
       " '2018',\n",
       " 'England',\n",
       " 'Wales',\n",
       " 'hour',\n",
       " 'Nine',\n",
       " 'five',\n",
       " 'first',\n",
       " 'first',\n",
       " 'annual',\n",
       " 'hours',\n",
       " 'hours',\n",
       " '2016',\n",
       " '2015',\n",
       " '2016',\n",
       " '2015',\n",
       " '2016',\n",
       " '2016',\n",
       " '2016',\n",
       " '2016',\n",
       " '2016']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print('Roberta Base Incorrect Predictions Snippet')\n",
    "wrong_preds[:50]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Roberta Base Incorrect Predictions Snippet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('106', '£1,313.9 billion'),\n",
       " ('approximately', '£42.8 billion'),\n",
       " ('2019', '3.4%'),\n",
       " ('502', '£4,101.5 billion'),\n",
       " (',', '£2,761.4 billion'),\n",
       " ('2', '£70.5 billion'),\n",
       " ('1', '1.7%'),\n",
       " ('GDP', '£25.8 billion'),\n",
       " ('2', '0.9%'),\n",
       " ('2016', '2018'),\n",
       " ('Scotland', 'the South East'),\n",
       " ('revenue', '£17.3 billion'),\n",
       " ('2019', '£214.4 billion'),\n",
       " ('%', '8.8%'),\n",
       " ('2017', '2019'),\n",
       " ('England', 'West Midlands'),\n",
       " ('London', 'Scotland'),\n",
       " ('Wales', 'East Midlands'),\n",
       " ('only', 'four'),\n",
       " ('England', 'West Midlands'),\n",
       " ('half', '£2.5 billion'),\n",
       " ('2017', '2.6%'),\n",
       " ('114', '£94.5 billion'),\n",
       " ('89', '£92 billion'),\n",
       " ('up', 'from late May 2021'),\n",
       " ('date', 'early June 2021'),\n",
       " ('22', '87%'),\n",
       " ('2000', 'June 2020'),\n",
       " ('half', '31%'),\n",
       " ('highest', 'over 60%'),\n",
       " ('2015', 'January 2021'),\n",
       " ('Australia', 'Wales'),\n",
       " ('Australia', 'early May 2021'),\n",
       " ('19', '87%'),\n",
       " ('other', 'four'),\n",
       " ('the', 'late March to'),\n",
       " ('April', 'early May 2021'),\n",
       " ('It', 'Scotland'),\n",
       " ('2010', 'early November 2020'),\n",
       " ('Canada', 'Northern Ireland'),\n",
       " ('2010', 'early November 2020'),\n",
       " ('The', 'Quarterly'),\n",
       " ('new', 'quarterly'),\n",
       " ('2018', '27 July to 9 August 2020'),\n",
       " ('25', '82%'),\n",
       " ('financially', 'the next three months'),\n",
       " ('least', '34%'),\n",
       " ('10', '34%'),\n",
       " ('half', '10%'),\n",
       " ('half', '37%')]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Electra"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import ElectraForMaskedLM, ElectraTokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "model = ElectraForMaskedLM.from_pretrained('google/electra-small-discriminator')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/electra_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/electra_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/electra_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/electra_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/electra_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/electra_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Examples: 6184\n",
      "Correct: 0, Incorrect: 6184\n",
      "Percentage Correct: 0.0%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Albert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
    "model = AlbertForMaskedLM.from_pretrained('albert-base-v2')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make sure to adjust RUN var \n",
    "# this section stores the most confident prediction\n",
    "# and also keeps track of all unique entities \n",
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    results = []\n",
    "    entity_set = set()\n",
    "    for row in tqdm(range(df.shape[0])):\n",
    "        row_result = []\n",
    "        clozes = [c for c in generate_clozes_from_point(df['point'][row], ne_answer_generator)]\n",
    "        [entity_set.add((x.answer_text, x.answer_type)) for x in clozes]\n",
    "        for cloze in clozes:\n",
    "            result = check_model(model, tokenizer, cloze.cloze_text)\n",
    "\n",
    "            answer_given = ''.join(result[0].get('token_str').split(' '))\n",
    "            confidence = result[0].get('score')\n",
    "            answer_true = cloze.answer_text\n",
    "\n",
    "            # saves\n",
    "            # prediction, confidence score, truth, dataframe row, cloze id\n",
    "            row_result.append((answer_given, confidence, answer_true, row, cloze.cloze_id))\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    with open('results/albert_base_check_model_july2.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    with open('results/albert_base_entity_set_july2.pickle', 'wb') as f:\n",
    "        pickle.dump(entity_set, f)\n",
    "\n",
    "    #  here I am saving the entities in a dictionary \n",
    "    #  with keys being each different entity category \n",
    "    #  such as MONEY, PERCENT and so on with values the unique terms found in our data\n",
    "\n",
    "    categories = [x[1] for x in list(entity_set)]\n",
    "    # construct keys\n",
    "    entities = dict()\n",
    "    entities = {f'{x}':[] for x in categories if x not in entities}\n",
    "    # append only unique values\n",
    "    [entities.get(x[1]).append(x[0]) for x in entity_set if x[0] not in entities.get(x[1])]\n",
    "\n",
    "    with open('results/albert_base_entity_dictionary.json', 'w') as f:\n",
    "        json.dump(entities, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# load back if you didn't run them\n",
    "\n",
    "with open('results/albert_base_check_model_july2.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/albert_base_entity_set_july2.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/albert_base_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Examples: 6184\n",
      "Correct: 216, Incorrect: 5968\n",
      "Percentage Correct: 3.493%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print('Albert Base Correct Predictions Snippet')\n",
    "correct_preds[:50]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Albert Base Correct Predictions Snippet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['year',\n",
       " '10%',\n",
       " '2019',\n",
       " '2018',\n",
       " '2018',\n",
       " '2018',\n",
       " '2017',\n",
       " '2017',\n",
       " '2016',\n",
       " '2017',\n",
       " '2016',\n",
       " '2017',\n",
       " '2016',\n",
       " '2016',\n",
       " '2015',\n",
       " 'annual',\n",
       " 'annual',\n",
       " '2018',\n",
       " '2018',\n",
       " 'first',\n",
       " '2016',\n",
       " '2015',\n",
       " '2016',\n",
       " '2015',\n",
       " '2016',\n",
       " '2016',\n",
       " 'year',\n",
       " 'annually',\n",
       " 'first',\n",
       " 'quarterly',\n",
       " 'annual',\n",
       " 'annual',\n",
       " '2017',\n",
       " '2018',\n",
       " '50%',\n",
       " 'annual',\n",
       " 'annual',\n",
       " 'annual',\n",
       " 'annual',\n",
       " 'first',\n",
       " 'annual',\n",
       " 'annual',\n",
       " '2019',\n",
       " '2018',\n",
       " '2018',\n",
       " '2018',\n",
       " '2017',\n",
       " '2018',\n",
       " '2016',\n",
       " '2017']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print('Albert Base Incorrect Predictions Snippet')\n",
    "wrong_preds[:50]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Albert Base Incorrect Predictions Snippet\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('2018', '2019'),\n",
       " ('20%', '£1,313.9 billion'),\n",
       " ('10%', '£42.8 billion'),\n",
       " ('€', '3.4%'),\n",
       " ('2021', '2018'),\n",
       " ('$500,000', '£4,101.5 billion'),\n",
       " ('2018', '£2,761.4 billion'),\n",
       " ('2020', '£70.5 billion'),\n",
       " ('34%', '1.7%'),\n",
       " ('2020', '£25.8 billion'),\n",
       " ('34%', '0.9%'),\n",
       " ('2011', '2018'),\n",
       " ('uk', 'the South East'),\n",
       " ('2019', '£17.3 billion'),\n",
       " ('2020', '£214.4 billion'),\n",
       " ('gdp', '8.8%'),\n",
       " ('2010', '2019'),\n",
       " ('lancashire', 'West Midlands'),\n",
       " ('yorkshire', 'Yorkshire'),\n",
       " ('lincolnshire', 'Scotland'),\n",
       " ('wales', 'East Midlands'),\n",
       " ('largest', 'four'),\n",
       " ('cambridgeshire', 'West Midlands'),\n",
       " ('10%', '£2.5 billion'),\n",
       " ('€', '2.6%'),\n",
       " ('2009', '£94.5 billion'),\n",
       " ('2010', '£92 billion'),\n",
       " ('up', 'from late May 2021'),\n",
       " ('2021', 'early June 2021'),\n",
       " ('2015:', '87%'),\n",
       " ('2001', 'June 2020'),\n",
       " ('40%', '31%'),\n",
       " ('unchanged', 'over 60%'),\n",
       " ('2010', 'January 2021'),\n",
       " ('evalle', 'Wales'),\n",
       " ('wales', 'early May 2021'),\n",
       " ('joyah', '87%'),\n",
       " ('three', 'four'),\n",
       " ('the', 'late March to'),\n",
       " ('april', 'early May 2021'),\n",
       " ('evalle', 'Scotland'),\n",
       " ('1981', 'early November 2020'),\n",
       " ('joyah', 'Northern Ireland'),\n",
       " ('2000', 'early November 2020'),\n",
       " ('the', 'Quarterly'),\n",
       " ('quarterly', 'annual'),\n",
       " ('empirical', 'quarterly'),\n",
       " ('2009:', '27 July to 9 August 2020'),\n",
       " ('metacritic', '82%'),\n",
       " ('sustainability', 'the next three months')]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Token Language Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "with open('results/RobertaForMaskedLM_20210714_192239_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "with open('results/RobertaForMaskedLM_20210714_192239_entity_set.pickle', 'rb') as f:\n",
    "    entity_set = pickle.load(f)\n",
    "with open('results/RobertaForMaskedLM_20210714_192239_entity_dictionary.json', 'r') as f:\n",
    "    entities = json.load(f)\n",
    "\n",
    "\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizerFast\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "count_correct, count_wrong = 0, 0\n",
    "correct_preds, wrong_preds = [], []\n",
    "\n",
    "for row in results:\n",
    "    if len(row):\n",
    "        for entry in row:\n",
    "            # THIS IS AN ISSUE!!\n",
    "            # IT SEEMS THAT THE MODEL PREDICTS A WHITESPACE AT THE START!!!\n",
    "            if entry[0][0] == ' ':\n",
    "                entry[0] = entry[0][1:]\n",
    "            if entry[0] == entry[2]:\n",
    "                count_correct += 1\n",
    "                correct_preds.append(entry[0])\n",
    "            else:\n",
    "                count_wrong += 1\n",
    "                wrong_preds.append((entry[0], entry[2]))\n",
    "\n",
    "print(f'Total Examples: {count_wrong + count_correct}')\n",
    "print(f'Correct: {count_correct}, Incorrect: {count_wrong}')\n",
    "print(f'Percentage Correct: {np.round( ((count_correct / (count_correct+ count_wrong) ) * 100), 3)}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Examples: 6184\n",
      "Correct: 654, Incorrect: 5530\n",
      "Percentage Correct: 10.576%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b9679e1c6c858221750b0560d352a46169916bc602dce44bbd2a48d631c8c5d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('comp0087': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}